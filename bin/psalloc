#!/bin/bash

set -e

self_dir="$( cd "$( dirname "${BASH_SOURCE[0]}" )" >/dev/null 2>&1 && pwd )"
source "${self_dir}"/pscommon.sh

if [[ "$#" -lt 6 ]]
then
	echo "Usage: $0 prefix arch mem_per_cpu nodes num_tasks max_max_time" 1>&2
	exit 1
fi

eprefix=$(cd -- "$1"/ && pwd)
arch=$2
gpu=$3
mem_per_cpu=$4
nodes=$5
tasks=$6
max_time=$7
shift 7

gpu_args() {
	if [[ -n "${gpu}" ]]
	then
		echo --gres=gpu:${gpu}
	fi
}

# /var/spool/slurm/slurm.conf
# SallocDefaultCommand="exec env PATH=/usr/bin:/bin srun -n1 -N1
# 	--export=HOME,PATH,TERM,USER --mem-per-cpu=0 --gres=gpu:0 --cpu_bind=no
# 	--pty --preserve-env --mpi=pmi2 ${DISPLAY:+--x11=first} $SHELL -l"
# --constraint IB: only Infiniband nodes work with /scratch, the Myrinet nodes hang
#    See ITS RITM0188766
args+=(--constraint "IB")
runexec salloc --nodes "${nodes}" --ntasks "${tasks}" \
	--constraint IB --constraint "$(constraint "${arch}")"  $(gpu_args) --mem-per-cpu "${mem_per_cpu}" \
	--time "${max_time}" \
	env PATH=/usr/bin:/bin srun -n1 -N1 \
	--export=HOME,PATH,TERM,USER --mem-per-cpu=${mem_per_cpu} $(gpu_args) --cpu_bind=no \
 	--pty --preserve-env $SHELL "${eprefix}"/startprefix -c "exec \"${eprefix}/bin/bash\" --rcfile \"${eprefix}\"/${RCFILE} -i"
