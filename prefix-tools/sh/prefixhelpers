print_args() {
	for i
	do
		if [[ -z "$i" ]]
		then
			echo -n "\"\" "
		elif [[ "$i" =~ ' ' ]]
		then
			echo -n "\"$i\" "
		else
			echo -n "$i "
		fi
	done
}

run() {
	print_args "$@"
	"$@"
}
rune() {
	print_args "$@"
	runeq "$@"
}
runeq() {
	local flags=$-
	set +e
	"$@"
	if [[ "$flags" =~ e ]]
	then set -e
	else set +e
	fi
}

# This is for printing the commands run in a capture statement.
# The use case is as follows:
#
#   function get_output() {
#       rund somecommand --with complicated args that produces output
#   }
#   DRY=1 get_output
#   the_output=$(get_output)
#
# The point is to not have to duplicate the command, and to not
# have to pass the command through arrays or strings (which is
# fragile due to the complicated quoting).
function rund() {
	local echo_prog
	if [[ -n "${DRY}" ]]
	then echo_prog=echo
	else echo_prog=""
	fi
	${echo_prog} "$@"
}


runexec() {
	print_args exec "$@"
	exec "$@"
}

constraint() {
	local CLUSTER=$1
	local ARCH=$2
	node_info "${CLUSTER}" "${ARCH}"
	echo "${FEAT}"
}

node_info() {
	local CLUSTER=$1
	local ARCH=$2

	case "${CLUSTER}" in
		hpcc)
			# Keeping nodes that disappeared, for reference
			local REMOVED=""
			case "$ARCH" in
				harpertown)
					FEAT="E5410"
					REMOVED=1
					;;
				westmere)
					FEAT="X5650"
					REMOVED=1
					;;
				sandybridge) # GPU: k20 ; ISI gpuk40c machine
					FEAT="E5-2665"
					MIN_CORES=16
					;;
				ivybridge)
					FEAT="E5-2650v2"
					REMOVED=1
					;;
				haswell) # GPU: k40
					FEAT="E5-2640v3"
					REMOVED=1
					;;
				broadwell) # GPU: p100
					FEAT="E5-2640v4"
					REMOVED=1
					;;
				skylake) # v100
					FEAT="gold-6130|silver-4116"
					REMOVED=1
					;;
				skylake-gold)
					FEAT="gold-6130"
					REMOVED=1
					;;
				skylake-silver)
					FEAT="silver-4116"
					REMOVED=1
					;;
				opteron) # Magny-Cours (no dedicated option);
					 # 'barcelona' ('amdfam10' is synonym)
					 # results in SIGILL
					FEAT="AMD6176"
					REMOVED=1
					;;
				any)
					FEAT=""
					MIN_CORES=12
					;;
				*)
					echo "ERROR: Arch ${ARCH} not in cluster ${CLUSTER}" 1>&2
					exit 1
					;;
			esac
			if [[ -n "${REMOVED}" ]]
			then
				echo "ERROR: Arch ${ARCH} no longer in cluster ${CLUSTER}" 1>&2
				exit 1
			fi
			# Restrict to Infiniband nodes, because Myrinet nodes
			# hang with /scratch See ITS Ticket RITM0188766; except
			# for Opteron, which are all on Myrinet.  Note that
			# multiple --constraints args are not allowed (later
			# override earlier) and --constraint cannot understand
			# an expression (nested parens with # precedence), it
			# gets converted into a list of features, with an
			# AND/OR/XAND/XOR "modifier" attached to each feature.
			# So, to achieve (f1|f2)&f3, passing 'f1|f2&f3' should
			# work.  See build_feature_list() in
			# src/slurmctld/job_scheduler.c
			#
			# Update: Myrinet (and Opteron) nodes have been removed.
			# Keeping this here just for reference.
			if [[ "${CLUSTER}" = hpcc ]]
			then
				if [[ "${ARCH}" != opteron ]]
				then
					echo "${FEAT}&IB"
				fi
			else
				echo "${FEAT}"
			fi
			;;
		discovery)
			# TODO: label these with what GPUs are hooked up to each
			case "$ARCH" in
			ivybridge)
				FEAT="xeon-2640v2"
				MIN_CORES=16
				;;
			haswell)
				FEAT="xeon-2640v3"
				MIN_CORES=16
				;;
			broadwell)
				FEAT="xeon-2640v4"
				MIN_CORES=20
				;;
			skylake)
				FEAT="xeon-6130|xeon-4116"
				MIN_CORES=24
				;;
			skylake-gold)
				FEAT="xeon-6130"
				MIN_CORES=32
				;;
			skylake-silver)
				FEAT="xeon-4116"
				MIN_CORES=24
				;;
			any)
				FEAT=""
				MIN_CORES=16
				;;
			*)
				echo "ERROR: arch ${ARCH} not in cluster ${CLUSTER}" 1>&2
				exit 1
				;;
			esac
			;;
		theta)
			case "${ARCH}" in
			knl)
				FEAT="" # not using SLURM...
				MIN_CORES=64
				;;
			*)
				echo "ERROR: arch ${ARCH} not in cluster ${CLUSTER}" 1>&2
				exit 1
				;;
			esac
			;;
		*)
			echo "ERROR: invalid cluster: ${CLUSTER}" 1>&2
			exit 1
			;;
	esac

	if [[ -z "${MIN_CORES}" ]] # internal error-catcher
	then
		echo "ERROR: MIN_CORES not set (check case above)" 1>&2
		exit 1
	fi
}

function get_free_space_mb
{
	echo $(($(stat -f --format="%a*%S" "$1") / (1024*1024)))
}

function check_space_mb
{
	local path=$1
	local space_mb=$2
	[[ "$(get_free_space_mb "${path}")" -ge "${min_space_mb}" ]]
}

# Set TMPDIR to a temporary directory to be used as build dir.  Uses directory
# allocated by resource manager if set, otherwise, looks at the path passed
# in TMPDIR and either uses it as is, or if it is empty or is detected to be a
# shared directory (e.g. /tmp or /dev/shm), then creates a subdirectory in
# one of these shared directories with mktemp, and registers a cleanup hook.
# Set THE_TMPDIR to override all of the selection logic except the subdirectory
# creation in case of shared directories.
#
# Cluster-specific defaults are used, but some require ROOT to be set to
# the prefix path.
#
# NOTE: This function replaces the EXIT trap handler. Be careful if you
# want to use this function and use EXIT trap handler from your script.
function set_tmpdir
{
	# All args are optional
	local cluster="$1"
	shift
	local min_space_mb="$1"
	shift
	local root="$1"
	shift
	echo TMPDIR=$TMPDIR

	if [[ -z "${min_space_mb}" ]]
	then
		if [[ -n "${SPACE_MB}" ]]
		then
			min_space_mb="${SPACE_MB}"
		else
			min_space_mb=1024
		fi
	fi

	if [[ -z "${THE_TMPDIR}" ]]
	then
		# Highest priority: use the tmp dir alloced to the job
		# by the resource manager
		if [[ -n "${SLURM_TMPDIR}" && -d "${SLURM_TMPDIR}" ]]
		then
			THE_TMPDIR="${SLURM_TMPDIR}"
		elif [[ -n "${__LSF_JOB_TMPDIR__}" && -d "${__LSF_JOB_TMPDIR__}" ]]
		then
			THE_TMPDIR="${__LSF_JOB_TMPDIR__}"
		elif [[ -n "${TMPDIR}" ]]
		then
			THE_TMPDIR="${TMPDIR}"
		fi
	fi

	# If still not set (or in special cases), then use a default
	if [[ -z "${THE_TMPDIR}" || \
			( "${cluster}" = "olcf-summit" && -z "${LSB_JOBID}" \
				&& "${THE_TMPDIR}" = "/tmp" ) ]]
	then
		case "${cluster}" in
		olcf-summit)
			# On Summit, on login machines, don't use (/tmp,
			# backed by tmpfs), because there is a memory usage
			# limit, which the build exceeds.  Instead, use the
			# same FS as the prefix (which is expected to be the
			# Spectrum parallel FS). Note: for worker machines we
			# won't get here since RM case above.
			if [[ -n "${root}" ]]
			then
				THE_TMPDIR="${root}"/var/tmp
			else
				echo "ERROR: temp dir selection failed: " \
					"refusing to use /tmp on Summit login machine," \
					"but prefix path was not given" 1>&2
				exit 1
			fi
			;;
		esac
	fi

	# If still not set, or set to a shared directory, try one
	# of the shared directories, checking for free space.

	# /tmp is not good enough, create a dedicated dir within /tmp
	function cleanup_tmp {
		if [[ -n "${THE_TMPDIR}" && -e "${THE_TMPDIR}" ]]
		then
			if [[ -z "${KEEP_TMPDIR}" ]]
			then
				rm -rf "${THE_TMPDIR}"
				echo "cleaned up TMPDIR=${THE_TMPDIR}"
			else
				echo "NOTICE: work dir ${THE_TMPDIR} kept, remove manually"
			fi
		fi
	}
	if [[ -z "${THE_TMPDIR}" || "${THE_TMPDIR}" =~ ^(/tmp|/dev/shm)$ ]]
	then
		local tmp_root
		if [[ -n "${min_space_mb}" ]]
		then
			if [ -n "${THE_TMPDIR}" ] && \
				check_space_mb "${THE_TMPDIR}" "${min_space_mb}"
			then
				tmp_root="${THE_TMPDIR}"
			elif check_space_mb /dev/shm "${min_space_mb}"
			then
				tmp_root=/dev/shm
			elif check_space_mb /tmp "${min_space_mb}"
			then
				tmp_root=/tmp
			else
				echo "ERROR: no temp dir has ${min_space_mb} MB of space" 1>&2
				exit 1
			fi
		else
			if [ -n "${THE_TMPDIR}" ]
			then
				tmp_root="${THE_TMPDIR}"
			else
				tmp_root=/tmp
			fi
		fi
		unset TMPDIR # otherwise mktemp ignores -p
		THE_TMPDIR=$(mktemp -p "${tmp_root}" -d -t $(whoami)-gpref-XXX)
		local TMPDIR_ACTION
		if [[ -z "${KEEP_TMPDIR}" ]]
		then
			TMPDIR_ACTION="cleanup"
		else
			TMPDIR_ACTION="keep"
		fi
		echo "created TMPDIR=${THE_TMPDIR} (will ${TMPDIR_ACTION})"
		# This cleanup is imprefect: if job is killed by resource
		# manager, the trash will remain. If we get to this case, then
		# we rely on the user to manually clean up. So, ideally, we
		# would not get to this case, i.e. resource manager would
		# allocate a temp dir and we use it above.

		# NOTE: this replaces the handler, not easy to append...
		trap cleanup_tmp EXIT
	fi

	# If still not set, we don't have any other options left
	if [[ -z "${THE_TMPDIR}" ]]
	then
		echo "ERROR: temp directory selection failed" 1>&2
		exit 2
	fi

	# Validate our selection
	if [[ ! -e "${THE_TMPDIR}" ]]
	then
		echo "ERROR: temp directory '${THE_TMPDIR}' does not exist" 1>&2
		exit 3
	fi
	if ! touch "${THE_TMPDIR}"/test_tmp
	then
		echo "ERROR: temp directory '${THE_TMPDIR}' not writable" 1>&2
		exit 4
	fi
	if ! check_space_mb "${THE_TMPDIR}" "${min_space_mb}"
	then
		echo "ERROR: temp directory '${THE_TMPDIR}'" \
			"has insufficient space (<= ${min_space_mb} MB)" 1>&2
		exit 5
	fi

	export TMPDIR="${THE_TMPDIR}"
	echo "TMPDIR=${TMPDIR} (free space >= ${min_space_mb} MB)"
}

# This is a function only in order to delay expansion of $TMPDIR
function with_portage_tmpdir {
	run env PORTAGE_TMPDIR=$TMPDIR $@
}

# parametrized by env vars: SPACE_MB and KEEP_TMPDIR and CLUSTER
function wtmp {
	(set_tmpdir "${CLUSTER}" && "$@")
}
function port {
	echo MAKEOPTS="${MAKEOPTS}"
	(set_tmpdir "${CLUSTER}" && with_portage_tmpdir "$@")
}
function sport {
	MAKEOPTS="-j1" port "$@"
}
function pport {
	MAKEOPTS="-j$(nproc)" port "$@"
}
function p4port { # useful on USC Discovery (usage capped at 4 cores @ 100%)
	MAKEOPTS="-j4" port "$@"
}

function profile_to_cluster {
	local CLUSTER=""
	if [[ "${PROFILE}" =~ generic ]]
	then
		CLUSTER=generic
	elif [[ "${PROFILE}" =~ usc-hpcc ]]
	then
		CLUSTER=usc-hpcc
	elif [[ "${PROFILE}" =~ usc-discovery ]]
	then
		CLUSTER=usc-discovery
	elif [[ "${PROFILE}" =~ anl-theta ]]
	then
		CLUSTER=anl-theta
	elif [[ "${PROFILE}" =~ olcf-summit ]]
	then
		CLUSTER=olcf-summit
	fi
	echo "${CLUSTER}"
}

function set_nproc {
	local CLUSTER="$1"
	case "${CLUSTER}" in

		olcf-summit)
                if [[ -n "${LSB_JOBID}" ]]; then
                        # On worker nodes, use all cores; note that jsrun
						# must be given --bind none and request all cores
						# (i.e. ALL_CPUS); then we set NPROC to fill only
						# one HW thread per core using the division here.
						local HW_THREADS_PER_CORE=4
                        NPROC=$(( $(nproc) / ${HW_THREADS_PER_CORE} ))
                else
                        # OLCF Summit login machines enforce a per-user limit
                        # of 16 HW thread, 16GB mem; base system builds with
                        # NPROC=16, but some packages in casper profile might
                        # not (handling this is WIP).
                        NPROC=16
                fi
                ;;
		# ANL Theta login machines are shared, but no limit is enforced
		anl-theta) NPROC=12 ;;

		# On HPCC Discovery cluster, nproc will return only as many
		# cores as have been requested from the resource manager.
		#
		# On USC HPCC legacy cluster nproc returns raw HW cores (not
		# 100% confirmed though), but it's harmless to use them all
		# regardless of requested number of processes for the job,
		# since a limit on processes is not enforced.
		usc-*) NPROC=$(nproc) ;;

		*) NPROC=$(nproc) ;;
	esac
}
